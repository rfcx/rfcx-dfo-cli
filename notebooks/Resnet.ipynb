{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfcx/rfcx-guardian-cli/blob/master/notebooks/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcWh7x4ndj19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "36a9c408-6d21-4969-9163-f2bce84b851f"
      },
      "source": [
        "!pip install tensorflow==2.0.0b1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0b1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (1.17.3)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.33.6)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0b1) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0b1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0b1) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1) (0.16.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjf9a0M5ehFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "edeaea28-81d1-4986-eef7-322eba55645e"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PrIGgeKeg6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "2f10a078-09d7-4b92-e923-720d29daf243"
      },
      "source": [
        "from google.colab import drive\n",
        "drive_mountpoint = '/content/data/'\n",
        "drive.mount(drive_mountpoint)\n",
        "%cd $drive_mountpoint/My\\ Drive/Colab\\ Notebooks\n",
        "%ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/data/\n",
            "/content/data/My Drive/Colab Notebooks\n",
            " 1-DatasetPrep.ipynb                          hitachi_nuttov3.tflite\n",
            "'2-Train backup.ipynb'                        \u001b[0m\u001b[01;34mhitachi_test_set\u001b[0m/\n",
            "'2-Train model.ipynb'                         \u001b[01;34mhitachi_train_set\u001b[0m/\n",
            "'2-Train model (tflite)'                      \u001b[01;34mkaggle2018_meow_bark_laugh\u001b[0m/\n",
            " 34fb7822-0ca6-4002-a233-9072c8c42607.wav     kaggle2018_meow_bark_laugh.tflite\n",
            " 3a46e1f5-f1d0-41f1-b771-64154be74f96.0.wav   \u001b[01;34mkaggle2018_train\u001b[0m/\n",
            "'3-Test model.ipynb'                          \u001b[01;34mlogs\u001b[0m/\n",
            "'4-Export tflite.ipynb'                       \u001b[01;34mmatt_run\u001b[0m/\n",
            " \u001b[01;34maudio_classification\u001b[0m/                        \u001b[01;34mrain-model\u001b[0m/\n",
            " \u001b[01;34maudio_upload_test\u001b[0m/                           Resnet.ipynb\n",
            " audio_urls.csv                               \u001b[01;34mreview_json\u001b[0m/\n",
            " chainsaw_vehicle.json                        rfcx-0.0.3-py3-none-any.whl\n",
            " \u001b[01;34mcheckpoints\u001b[0m/                                 rfcx-0.0.4-py3-none-any.whl\n",
            " confusion_matrix.txt                         \u001b[01;34mrfcx_example\u001b[0m/\n",
            " Data-preparation.ipynb                      'SDK tutorial.ipynb'\n",
            " \u001b[01;34mFSDKaggle2018.audio_test\u001b[0m/                    \u001b[01;34mservices\u001b[0m/\n",
            " \u001b[01;34mgunshot_dataset\u001b[0m/                             \u001b[01;34mSpectrogram\u001b[0m/\n",
            " \u001b[01;34mgunshot_model_v1\u001b[0m/                            \u001b[01;34mspeech_commands\u001b[0m/\n",
            " \u001b[01;34mHitachi_ant\u001b[0m/                                 \u001b[01;34mspeech_commands2\u001b[0m/\n",
            " hitachi_ant.pb                               SpeechCommands2.ipynb\n",
            " hitachi_ant.tflite                           SpeechCommands-ConvertTF2.ipynb\n",
            " \u001b[01;34mHitachi_modelv1\u001b[0m/                             SpeechCommands.ipynb\n",
            " \u001b[01;34mHitachi_modelv1-2nutto\u001b[0m/                      \u001b[01;34mspider-monkey-model-v2-nutto\u001b[0m/\n",
            " Hitachi_modelv1.tflite                       \u001b[01;34mtest_audio_set\u001b[0m/\n",
            " hitachi_nuttov3b.tflite                      Training-model.ipynb\n",
            " hitachi_nuttov3.pb                           wanted_confusion_matrix.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfSEsBWNegw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "ea964d3b-257f-48ad-8450-6ef25878c993"
      },
      "source": [
        "#@title Insert train dataset path and test data set path\n",
        "\n",
        "train_dataset_directory = \"gunshot_dataset/train_set/\" #@param {type:\"string\"}\n",
        "test_dataset_directory = \"gunshot_dataset/test_set/\" #@param {type:\"string\"}\n",
        "train_classes = os.listdir(train_dataset_directory)\n",
        "test_classes = os.listdir(test_dataset_directory)\n",
        "print('Found classes in train: ' + ', '.join(train_classes))\n",
        "print('Found classes in test: ' + ', '.join(test_classes))\n",
        "\n",
        "train_dataset = list()\n",
        "test_dataset = list()\n",
        "\n",
        "for c in train_classes:\n",
        "  train_dataset.extend([[c+'/'+x, c] for x in os.listdir(train_dataset_directory + c) if re.search(\"\\.[0-9]+\\.wav$\", x)])\n",
        "\n",
        "for c in test_classes:\n",
        "  test_dataset.extend([[c+'/'+x, c] for x in os.listdir(test_dataset_directory + c) if re.search(\"\\.[0-9]+\\.wav$\", x)])\n",
        "\n",
        "print('Examples train dataset:', train_dataset[1600:0:-100])\n",
        "print('Examples test dataset:', test_dataset[10:1000:100])\n",
        "print('Size of train dataset', len(train_dataset))\n",
        "print('Size of test dataset', len(test_dataset))\n",
        "print('Total size of dataset', len(train_dataset) + len(test_dataset))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found classes in train: gunshot, environment\n",
            "Found classes in test: gunshot, environment\n",
            "Examples train dataset: [['environment/Jk2B7Mvh6cE.109.wav', 'environment'], ['gunshot/dqJWTzC3s8I.106.wav', 'gunshot'], ['gunshot/cKK0oZrwed8.33.wav', 'gunshot'], ['gunshot/bciLCctZfjE.101.wav', 'gunshot'], ['gunshot/7RlyBtFDd98.78.wav', 'gunshot'], ['gunshot/3PfWjclBA5I.16.wav', 'gunshot'], ['gunshot/--aaILOrkII.103.wav', 'gunshot'], ['gunshot/YjNQ5TGRChs.30.wav', 'gunshot'], ['gunshot/wdVYP2ijnew.101.wav', 'gunshot'], ['gunshot/u_Nxu8TvonA.101.wav', 'gunshot'], ['gunshot/SLAmK__qyXM.15.wav', 'gunshot'], ['gunshot/QH3RIg1ypDg.29.wav', 'gunshot'], ['gunshot/nWlDkrIzc0g.107.wav', 'gunshot'], ['gunshot/l6HsxUNdkd4.17.wav', 'gunshot'], ['gunshot/JfQZeAIHg3s.70.wav', 'gunshot'], ['gunshot/hmD1w6133Og.102.wav', 'gunshot']]\n",
            "Examples test dataset: [['gunshot/2ffgd7k0vI8.45.wav', 'gunshot'], ['gunshot/Dj9gyAoqmQ0.35.wav', 'gunshot'], ['gunshot/M7rGKqfZh6k.31.wav', 'gunshot'], ['gunshot/UN84r_4GTdQ.27.wav', 'gunshot'], ['environment/2jFE-MKRmPw.43.wav', 'environment'], ['environment/DIxTruxPbdk.50.wav', 'environment'], ['environment/Jk2B7Mvh6cE.70.wav', 'environment'], ['environment/QbY5RyLsWVM.108.wav', 'environment'], ['environment/vQWFMfbDJyI.52.wav', 'environment']]\n",
            "Size of train dataset 3484\n",
            "Size of test dataset 873\n",
            "Total size of dataset 4357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHOSXHkVegfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "237a781f-8658-401b-c371-c55c7931ece7"
      },
      "source": [
        "# read_wav function for reading raw audio data\n",
        "from importlib.machinery import SourceFileLoader\n",
        "read_wav = SourceFileLoader('ReadWav' , 'services/AudioIference/AudioInference.py').load_module().ReadWav\n",
        "\n",
        "# test the read_wav function\n",
        "waveform, source_sample_rate = read_wav(train_dataset_directory + train_dataset[0][0])\n",
        "print(source_sample_rate)\n",
        "print(waveform.size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12000\n",
            "24000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTFDfzzCgGdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_x_sample(record, data_dir):\n",
        "  path = data_dir + record[0]\n",
        "  waveform, _ = read_wav(path)\n",
        "  return waveform[:, np.newaxis]\n",
        "\n",
        "def make_y_sample(record):\n",
        "  return 0 if record[1] == 'environment' else 1\n",
        "\n",
        "train_x = np.array([make_x_sample(x, train_dataset_directory) for x in train_dataset], dtype=np.float32)\n",
        "train_y = np.array([make_y_sample(y) for y in train_dataset], dtype=np.int64)\n",
        "test_x = np.array([make_x_sample(x, test_dataset_directory) for x in test_dataset], dtype=np.float32)\n",
        "test_y = np.array([make_y_sample(y) for y in test_dataset], dtype=np.int64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgQ1VQSHgGRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 53\n",
        "context_duration_seconds = 2.0\n",
        "sample_rate = 12000 # relate to audio sample rate\n",
        "number_of_classes = len(train_classes)\n",
        "\n",
        "context_duration_samples = int(context_duration_seconds * sample_rate)\n",
        "context_step_samples = context_duration_samples // 2\n",
        "  \n",
        "@tf.function\n",
        "def front_end(waveform):\n",
        "\n",
        "  # Remove channels\n",
        "  #mono = tf.reduce_mean(waveform, axis=1)\n",
        "  mono = tf.squeeze(waveform, 2)\n",
        "  \n",
        "  # Generate spectrograms\n",
        "  full_spectrograms = tf.signal.stft(\n",
        "      mono, frame_length=1024, frame_step=256, fft_length=1024)\n",
        "  magnitude_spectrograms = tf.math.abs(full_spectrograms)\n",
        "  log_spectrograms = tf.math.log(magnitude_spectrograms + 1e-6)\n",
        " \n",
        "  # Put the channel back in\n",
        "  result = tf.expand_dims(log_spectrograms, 3)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh0fVMZ5gGGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "660ee66c-0a45-4240-fed8-77f6929b41e3"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "def res_net_block(input_data, filters, conv_size):\n",
        "  x = layers.Conv2D(filters, conv_size, activation='relu', padding='same')(input_data)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(filters, conv_size, activation=None, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Add()([x, input_data])\n",
        "  x = layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "inputs = keras.Input(shape=(24000, 1))\n",
        "spectrogram = layers.Lambda(front_end)(inputs)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(spectrogram)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "num_res_net_blocks = 10\n",
        "for i in range(num_res_net_blocks):\n",
        "    x = res_net_block(x, 64, 3)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "res_net_model = keras.Model(inputs, outputs)\n",
        "\n",
        "res_net_model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 24000, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 90, 513, 1)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 88, 511, 32)  320         lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 86, 509, 64)  18496       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 28, 169, 64)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 169, 64)  36928       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 169, 64)  256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 28, 169, 64)  36928       batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 169, 64)  256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 28, 169, 64)  0           batch_normalization_1[0][0]      \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 28, 169, 64)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 169, 64)  36928       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 169, 64)  256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 169, 64)  36928       batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 28, 169, 64)  256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 28, 169, 64)  0           batch_normalization_3[0][0]      \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 28, 169, 64)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 28, 169, 64)  36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 169, 64)  256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 28, 169, 64)  36928       batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 28, 169, 64)  256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 28, 169, 64)  0           batch_normalization_5[0][0]      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 28, 169, 64)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 169, 64)  36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 169, 64)  256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 169, 64)  36928       batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 28, 169, 64)  256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 169, 64)  0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 28, 169, 64)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 169, 64)  36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 169, 64)  256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 169, 64)  36928       batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 169, 64)  256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 169, 64)  0           batch_normalization_9[0][0]      \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 28, 169, 64)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 169, 64)  36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 169, 64)  256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 28, 169, 64)  36928       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 169, 64)  256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 169, 64)  0           batch_normalization_11[0][0]     \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 28, 169, 64)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 28, 169, 64)  36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 169, 64)  256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 28, 169, 64)  36928       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 169, 64)  256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 169, 64)  0           batch_normalization_13[0][0]     \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 28, 169, 64)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 28, 169, 64)  36928       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 169, 64)  256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 169, 64)  36928       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 169, 64)  256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 169, 64)  0           batch_normalization_15[0][0]     \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 28, 169, 64)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 28, 169, 64)  36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 169, 64)  256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 28, 169, 64)  36928       batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 169, 64)  256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 28, 169, 64)  0           batch_normalization_17[0][0]     \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 28, 169, 64)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 28, 169, 64)  36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 169, 64)  256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 28, 169, 64)  36928       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 28, 169, 64)  256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 28, 169, 64)  0           batch_normalization_19[0][0]     \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 28, 169, 64)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 26, 167, 64)  36928       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 64)           0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          16640       global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 818,634\n",
            "Trainable params: 816,074\n",
            "Non-trainable params: 2,560\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiKr8_i_gF56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_net_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqaqcSCVgFti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "36dd6f56-e884-48fc-f1b4-085c5de48b32"
      },
      "source": [
        "res_net_model.fit(train_x, train_y, validation_split=0.1, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 3135 samples, validate on 349 samples\n",
            "Epoch 1/10\n",
            "1824/3135 [================>.............] - ETA: 20:59 - loss: 0.9037 - accuracy: 0.5433"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxLr-FynNPey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate_value = model.evaluate(test_x, test_y, batch_size = batch_size, verbose = 1)\n",
        "\n",
        "print('Evaluation value: {}'.format(evaluate_value))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}